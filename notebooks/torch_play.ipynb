{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ira/code/projects/nn-play\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/projects/nn-play/\n",
    "from structured_container import DataContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EP_LEN = 100\n",
    "nc = 1\n",
    "ndf = 32\n",
    "ngf = 32\n",
    "nz = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data-balls/bounce-valid.pt\n"
     ]
    }
   ],
   "source": [
    "data_test = DataContainer('data-balls/bounce-valid.pt', batch_size=BATCH_SIZE, ep_len_read=EP_LEN)\n",
    "data_test.populate_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netD(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(_netD, self).__init__()\n",
    "        self.nn_seq = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 3, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.nn_seq(x)\n",
    "\n",
    "        return output.view(-1, 1)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6079\n",
       "[torch.FloatTensor of size 1x1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = _netD()\n",
    "netD.apply(weights_init)\n",
    "x = Variable(torch.randn(1,nc,28,28))\n",
    "out = netD(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_netG, self).__init__()\n",
    "        self.nn_seq = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "#             nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "#             nn.BatchNorm2d(ngf * 8),\n",
    "#             nn.ReLU(True),\n",
    "#             # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 2, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            # nn.Tanh()\n",
    "            nn.Sigmoid()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.nn_seq(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netG = _netG()\n",
    "netG.apply(weights_init)\n",
    "x = Variable(torch.randn(1, nz, 1, 1))\n",
    "out = netG(x)\n",
    "out;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "input = torch.FloatTensor(BATCH_SIZE, nc, 28, 28)\n",
    "noise = torch.FloatTensor(BATCH_SIZE, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(BATCH_SIZE, nz, 1, 1).normal_(0, 1)\n",
    "label = torch.FloatTensor(BATCH_SIZE)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netD.cuda()\n",
    "netG.cuda()\n",
    "criterion.cuda()\n",
    "input, label = input.cuda(), label.cuda()\n",
    "noise, fixed_noise = noise.cuda(), fixed_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = Variable(input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002)\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_cycle():\n",
    "    x = data_test.get_n_random_images(BATCH_SIZE)\n",
    "    x = x.transpose((0, 3, 1, 2))\n",
    "    x = torch.FloatTensor(x)\n",
    "\n",
    "    ############################\n",
    "    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "    ###########################\n",
    "    # train with real\n",
    "    netD.zero_grad()\n",
    "    real_cpu = x\n",
    "    batch_size = real_cpu.size(0)\n",
    "    input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "    label.data.resize_(batch_size).fill_(real_label)\n",
    "\n",
    "    output = netD(input)\n",
    "    errD_real = criterion(output, label)\n",
    "    errD_real.backward()\n",
    "    D_x = output.data.mean()\n",
    "    print(\"D_x\", D_x)\n",
    "\n",
    "    # train with fake\n",
    "    noise.data.resize_(batch_size, nz, 1, 1)\n",
    "    noise.data.normal_(0, 1)\n",
    "    fake = netG(noise)\n",
    "    label.data.fill_(fake_label)\n",
    "    output = netD(fake.detach())\n",
    "    errD_fake = criterion(output, label)\n",
    "    errD_fake.backward()\n",
    "    D_G_z1 = output.data.mean()\n",
    "    errD = errD_real + errD_fake\n",
    "    optimizerD.step()\n",
    "    \n",
    "    print(\"D_G_z1\", D_G_z1)\n",
    "    \n",
    "    ############################\n",
    "    # (2) Update G network: maximize log(D(G(z)))\n",
    "    ###########################\n",
    "    netG.zero_grad()\n",
    "    label.data.fill_(real_label)  # fake labels are real for generator cost\n",
    "    output = netD(fake)\n",
    "    errG = criterion(output, label)\n",
    "    errG.backward()\n",
    "    D_G_z2 = output.daqta.mean()\n",
    "    optimizerG.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_x 0.9787691831588745\n",
      "D_G_z1 0.000985470018349588\n"
     ]
    }
   ],
   "source": [
    "train_D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
